{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import combinations\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('filtered_data.csv')\n",
    "\n",
    "# Get the column names\n",
    "all_columns = ['COM-1', 'COM-2', 'POP-1', 'STA-1', 'STA-2', 'STA-3', 'STA-4', 'STA-5', 'STA-6', 'STA-7', 'STA-8', 'STA-9', 'TEC-1', 'TEC-2', 'TEC-3', 'TEC-4']\n",
    "\n",
    "# Dictionary to store scores for each combination\n",
    "scores_dict = {}\n",
    "\n",
    "# Number of iterations\n",
    "num_iterations = 100\n",
    "\n",
    "# Run the process multiple times\n",
    "for _ in range(num_iterations):\n",
    "    for x_columns_size in range(1, len(all_columns) + 1):\n",
    "        for x_columns_combination in combinations(all_columns, x_columns_size):\n",
    "            # Check if the combination size is 1\n",
    "            if len(x_columns_combination) == 1:\n",
    "                # Extract features (X) and target (y)\n",
    "                X_features = data[list(x_columns_combination)]\n",
    "                for y_column in all_columns:\n",
    "                    if y_column not in x_columns_combination:\n",
    "                        y_target = data[y_column]\n",
    "\n",
    "                        # Split the data into training and testing sets\n",
    "                        X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.2)\n",
    "\n",
    "                        # Perform linear regression\n",
    "                        model = LinearRegression()\n",
    "                        model.fit(X_train, y_train)\n",
    "\n",
    "                        # Calculate the score\n",
    "                        score = model.score(X_test, y_test)\n",
    "\n",
    "                        # Store the score in the dictionary\n",
    "                        key = f\"X:{x_columns_combination[0]}, y:{y_column}\"\n",
    "                        if key not in scores_dict:\n",
    "                            scores_dict[key] = []\n",
    "                        scores_dict[key].append(score)\n",
    "\n",
    "# Print the average scores for each combination\n",
    "for key, scores in scores_dict.items():\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"{key}, Average Score: {average_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the Scatter plot to check relationship between Sal and Temp\n",
    "sns.lmplot(x =\"Horizontal\", y =\"Vertical\", data = df_binary, order = 2, ci = None)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and fit the logistic regression model with increased max_iter\n",
    "regr = LogisticRegression(max_iter=1000)\n",
    "regr.fit(X_train_scaled, y_train.ravel())\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "y_pred = regr.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = regr.score(X_test_scaled, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create and fit the neural network model\n",
    "mlp_classifier = MLPClassifier()\n",
    "mlp_classifier.fit(X_train, y_train.ravel())\n",
    "\n",
    "# Evaluate the model\n",
    "print(mlp_classifier.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X is your feature matrix\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose a range of values for k\n",
    "k_values = range(2, 20)\n",
    "\n",
    "# Calculate the silhouette score for each value of k\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "\n",
    "# Plot the silhouette scores\n",
    "plt.plot(k_values, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score vs. Number of Clusters')\n",
    "plt.show()\n",
    "\n",
    "# Choose the optimal k (e.g., from the elbow method)\n",
    "optimal_k = 3\n",
    "\n",
    "# Apply k-means clustering\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to the original dataset\n",
    "df_clustered = df.copy()\n",
    "df_clustered['Cluster'] = clusters\n",
    "\n",
    "# Explore characteristics of each cluster\n",
    "for cluster_id in range(optimal_k):\n",
    "    cluster_data = df_clustered[df_clustered['Cluster'] == cluster_id]\n",
    "    print(f'\\nCluster {cluster_id}:\\n')\n",
    "    print(cluster_data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X and y are your feature and target variables\n",
    "# X, y = ...\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the AutoML regressor\n",
    "automl = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task=120, per_run_time_limit=30, n_jobs=-1)\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = automl.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Access additional information about the AutoML process\n",
    "print(automl.sprint_statistics())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7209302325581395\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  sustainable       0.69      0.92      0.79        24\n",
      "unsustainable       0.82      0.47      0.60        19\n",
      "\n",
      "     accuracy                           0.72        43\n",
      "    macro avg       0.75      0.70      0.69        43\n",
      " weighted avg       0.75      0.72      0.70        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load your dataset into a DataFrame (replace 'data.csv' with your actual dataset file)\n",
    "df = pd.read_csv('filtered_data.csv')\n",
    "\n",
    "\n",
    "# Calculate the percentage decrease for each indicator\n",
    "df['Percentage_Decrease'] = ((df['STA-2'] - df['STA-2'].shift(1)) / df['STA-2'].shift(1)) * 100\n",
    "\n",
    "# Define a binary target variable based on 20% decrease threshold\n",
    "df['Sustainability'] = df['Percentage_Decrease'].apply(lambda x: 'unsustainable' if x >= -20 else 'sustainable')\n",
    "\n",
    "# Drop the first row as it doesn't have a previous value for percentage calculation\n",
    "df = df.dropna()\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df[['STA-2']]  # Features\n",
    "y = df['Sustainability']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the test data\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print a classification report for more detailed metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
